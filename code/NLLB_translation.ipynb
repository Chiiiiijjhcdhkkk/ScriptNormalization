{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This script employs Facebook's NLLB model with HuggingFace for machine translation.\n",
        "\n",
        "(Source: https://github.com/sinaahmadi/ScriptNormalization)"
      ],
      "metadata": {
        "id": "Vv_8JXYTYs2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install --quiet bitsandbytes\n",
        "!pip install --quiet --upgrade accelerate"
      ],
      "metadata": {
        "id": "DjwrFk07_Rr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "kosn8gyrlBoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iSStiaE-63r"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\").cuda()\n",
        "model.device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator_ckb = pipeline('translation', model=model, tokenizer=tokenizer, src_lang='ckb_Arab', tgt_lang='eng_Latn', max_length = 400, device=model.device, num_beams=3, early_stopping=True)\n",
        "translator_kas = pipeline('translation', model=model, tokenizer=tokenizer, src_lang='kas_Arab', tgt_lang='eng_Latn', max_length = 400, device=model.device, num_beams=3, early_stopping=True)\n",
        "translator_snd = pipeline('translation', model=model, tokenizer=tokenizer, src_lang='snd_Arab', tgt_lang='eng_Latn', max_length = 400, device=model.device, num_beams=3, early_stopping=True)\n"
      ],
      "metadata": {
        "id": "9M5ZkPb-_XrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f_name in [\"Sorani-Arabic\", \"Sorani-Persian\", \"Kashmiri-Urdu\", \"Sindhi-Urdu\"]:\n",
        "  for n in [\"20\", \"40\", \"60\", \"80\", \"100\"]:\n",
        "    for t in [\"src\", \"normalized.src\", \"trg\"]:\n",
        "      print(f_name, n, t)\n",
        "      # read the file\n",
        "      with open(\"%s/devtest_%s.%s\"%(f_name, n, t), \"r\") as f:\n",
        "        text = f.read().splitlines()\n",
        "      print(\"Input length: \", len(text))\n",
        "      # translate the file\n",
        "      trans_text = list()\n",
        "      if \"Sorani\" in f_name:\n",
        "        trans_text = translator_ckb(text)\n",
        "      elif \"Sindhi\" in f_name:\n",
        "        trans_text = translator_snd(text)\n",
        "      else:\n",
        "        trans_text = translator_kas(text)\n",
        "      \n",
        "      trans_text = [i[\"translation_text\"] for i in trans_text]\n",
        "      #print(text)\n",
        "      #print(trans_text)\n",
        "      # save the translation\n",
        "      print(len(trans_text))\n",
        "      with open(\"%s/devtest_%s.translated.%s\"%(f_name, n, t), \"w\") as f:\n",
        "        f.write(\"\\n\".join(trans_text))"
      ],
      "metadata": {
        "id": "Mm6Ze5lH_2bm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}